# Required: any Hugging Face model ID (base or fine-tuned)
MODEL_ID=mistralai/Mistral-7B-Instruct-v0.3

# vllm (recommended on GPU) or transformers
INFERENCE_BACKEND=vllm

# API defaults
HOST=0.0.0.0
PORT=8000
MAX_NEW_TOKENS=128
TEMPERATURE=0.7
TOP_P=0.95

# Guardrails
ENABLE_GUARDRAILS=true
MAX_PROMPT_CHARS=4000
MAX_REQUEST_NEW_TOKENS=512
# Comma-separated list. Example: bomb,credit card,password dump
BLOCKED_TERMS=

# Model loading options
TRUST_REMOTE_CODE=false
TENSOR_PARALLEL_SIZE=1
GPU_MEMORY_UTILIZATION=0.9

# Quantization options
# QUANTIZATION can be: none, int8, int4, awq, gptq, bitsandbytes
QUANTIZATION=none
# Optional explicit bits for transformers backend: 4 or 8
QUANTIZATION_BITS=0

# Optional: needed for private or gated models
HF_TOKEN=
